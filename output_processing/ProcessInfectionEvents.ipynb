{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "#try: import simplejson as json\n",
    "#except ImportError: import json\n",
    "from joblib import Parallel, delayed\n",
    "from joblib.pool import has_shareable_memory\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import time\n",
    "import lz4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_infection_events_to_data_frame(filename='infection.events.json'):\n",
    "    def read_infection_events():\n",
    "        with open(filename, 'rb') as f:\n",
    "            for line in f:\n",
    "                yield(json.loads(line))\n",
    "    infections = pd.DataFrame.from_dict(read_infection_events())\n",
    "    infections.loc[infections.symptomatic < 1, 'symptomatic'] = None\n",
    "    infections.person = infections.person.astype(np.int64)\n",
    "    return(infections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit -n1 -r1\n",
    "infections = read_infection_events_to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit -n1 -r1\n",
    "population_original = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_synth_people.txt')\n",
    "households_original = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_synth_households.txt')\n",
    "workplaces = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_workplaces.txt')\n",
    "schools = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_schools.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population = population_original.copy()\n",
    "population = population.reset_index()\n",
    "population['person'] = population.index\n",
    "population['age_group'] = pd.cut(population.age, bins=range(0,120,10), include_lowest=True, right=False)\n",
    "#population['age_group'] = pd.cut(population.age, bins=[0,2,18,65,120], include_lowest=True, right=False)\n",
    "\n",
    "apollo_locations = pd.DataFrame.from_csv('ApolloLocationCode.to.FIPSstcotr.csv')\n",
    "apollo_locations.reset_index(level=0, inplace=True)\n",
    "\n",
    "households = households_original.copy().reset_index()\n",
    "households['stcotr'] = (households.stcotrbg/10).astype(np.int64)\n",
    "households = pd.merge(households, apollo_locations, on='stcotr', how='inner', suffixes=('','_'), copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_dict = dict(\n",
    "    N = 'number of individuals',\n",
    "    S = 'susceptible', E = 'exposed', I = 'infectious',\n",
    "    Y = 'symptomatic', R = 'recovered', IS = 'infectious and symptomatic'\n",
    ")\n",
    "population_dict = dict(\n",
    "    # FRED currently just numbers persons sequentially as they are read from the synthetic population file\n",
    "    # rather than using the unique p_id provided in the synth population.  This should be changed, but until it\n",
    "    # is, we can't use the p_id.  Instead, see cell above for 'person' sequential id column.\n",
    "    #person = 'p_id', \n",
    "    race = 'race',\n",
    "    age_group = 'age_group',\n",
    "    age = 'age',\n",
    "    gender = 'sex'\n",
    ")\n",
    "household_dict = dict(\n",
    "    income = 'hh_income',\n",
    "    #location = 'stcotrbg',\n",
    "    #location = 'stcotr',\n",
    "    location = 'apollo_location_code'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_population(population, households, groupby_attributes): \n",
    "\n",
    "    _rev_population_dict = {population_dict[x]:x for x in groupby_attributes if x in population_dict}\n",
    "    _rev_population_dict.update({'person':'person'})\n",
    "    \n",
    "    _rev_household_dict = {household_dict[x]:x for x in groupby_attributes if x in household_dict}\n",
    "\n",
    "    _population = pd.merge(population[_rev_population_dict.keys() + ['hh_id']],\n",
    "                           households[_rev_household_dict.keys() + ['hh_id']],\n",
    "                           on='hh_id', suffixes=('', '.h'), how='inner',\n",
    "                           copy=True)[_rev_population_dict.keys() + _rev_household_dict.keys()]\n",
    "    \n",
    "    _population.rename(columns=_rev_population_dict, inplace=True, copy=False)\n",
    "    _population.rename(columns=_rev_household_dict, inplace=True, copy=False)\n",
    "\n",
    "    for k in groupby_attributes:\n",
    "        if k not in list(_population.columns):\n",
    "            raise Exception('Unable to group by key: %s' % k)\n",
    "    \n",
    "    return _population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_infections(group_data_frame, times, incidence=['N','S','E','I','Y','R','IS'],\n",
    "                     prevalence=['N','S','E','I','Y','R','IS'], grouping_keys={}):\n",
    "    \n",
    "    local_infections = pd.merge(infections, group_data_frame,\n",
    "                                on='person', how='inner', suffixes=('','_'), copy=True)\n",
    "\n",
    "    total_local_persons = len(group_data_frame.index)\n",
    "    \n",
    "    def get_incidence(local_infections, state, day):\n",
    "        if state == 'IS':\n",
    "            return len(local_infections[(day == local_infections.infectious) & \\\n",
    "                                        (day == local_infections.symptomatic)].index)\n",
    "        elif state == 'N':\n",
    "            return 0\n",
    "        else:\n",
    "            s = state_dict[state]\n",
    "            return len(local_infections[local_infections[s]==day].index)\n",
    "\n",
    "    def get_prevalence(local_infections, states, day):\n",
    "        if states is not None and isinstance(states, list) and len(states) > 0:\n",
    "            mask = {'NOT_S': (day >= local_infections.exposed) & \\\n",
    "                             (day < local_infections.susceptible)}\n",
    "            if set(['E','I','Y','R','IS']).intersection(set(states)):\n",
    "                mask['E'] = (mask['NOT_S'] & (day < local_infections.infectious))\n",
    "            if 'I' in states:\n",
    "                mask['I'] = (mask['NOT_S'] & (day >= local_infections.infectious)) & \\\n",
    "                            (day < local_infections.recovered)\n",
    "            if 'Y' in states:\n",
    "                mask['Y'] = (mask['NOT_S'] & (day >= local_infections.symptomatic)) & \\\n",
    "                            (day < local_infections.recovered)\n",
    "            if 'R' in states:\n",
    "                mask['R'] = (mask['NOT_S'] & (day >= local_infections.recovered)) & \\\n",
    "                            (day < local_infections.susceptible)\n",
    "            if 'IS' in states:\n",
    "                mask['IS'] = mask['I'] & mask['Y']\n",
    "           \n",
    "        for state in states:\n",
    "            if state is None:\n",
    "                raise Exception('No state specified!')\n",
    "            elif state == 'S':\n",
    "                yield (state, total_local_persons - len(local_infections[mask['NOT_S']].index))\n",
    "            elif state == 'N':\n",
    "                yield (state, total_local_persons)\n",
    "            else:\n",
    "                try:\n",
    "                    if total_local_persons == len(local_infections[mask['NOT_S']].index):\n",
    "                        yield (state, 0)\n",
    "                    else:\n",
    "                        yield (state, len(local_infections[mask[state]].index))\n",
    "                except:\n",
    "                    raise Exception('Unknown prevalence state requested %s!' % state)\n",
    "\n",
    "    rows = []\n",
    "    for t in times:\n",
    "        row = dict(day = t)\n",
    "        row.update({k + '_i': get_incidence(local_infections, k, t) for k in incidence})\n",
    "        row.update({k + '_p': v for k,v in get_prevalence(local_infections, prevalence, t)})\n",
    "        if grouping_keys:\n",
    "            row.update(grouping_keys)\n",
    "        rows.append(row)\n",
    "    \n",
    "    return lz4.dumps(json.dumps(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def apply_query_infections(population, households, times,\n",
    "                           incidence=['N','S','E','I','Y','R','IS'],\n",
    "                           prevalence=['N','S','E','I','Y','R','IS'],\n",
    "                           group_by_keys=['age','race'],\n",
    "                           parallel=True):\n",
    "    \n",
    "    pop = query_population(population, households, group_by_keys)\n",
    "    grouped_persons = pop.groupby(group_by_keys)\n",
    "    grouping_keys = grouped_persons.grouper.names\n",
    "\n",
    "    if parallel:\n",
    "        n_jobs = multiprocessing.cpu_count()\n",
    "        \n",
    "        # NOTE: The \"mmap_mode='c'\" argument (copy-on-write) is necessary for\n",
    "        # processing groupby (which are MemeoryViews) even if you're not \n",
    "        # writing to them! This is crazy!\n",
    "        result_list = Parallel(n_jobs=n_jobs, mmap_mode='c')(\n",
    "            delayed(query_infections)(      \n",
    "                group_data_frame,\n",
    "                times, incidence, prevalence,\n",
    "                {k:v for k,v in zip(\n",
    "                        grouping_keys,\n",
    "                        grouping_values if isinstance(grouping_values, tuple) \\\n",
    "                                        else (grouping_values,))\n",
    "                }) for grouping_values, group_data_frame in grouped_persons)\n",
    "    else:\n",
    "        result_list = [query_infections(      \n",
    "                group_data_frame,\n",
    "                times, incidence, prevalence,\n",
    "                {k:v for k,v in zip(\n",
    "                        grouping_keys,\n",
    "                        grouping_values if isinstance(grouping_values, tuple) \\\n",
    "                                        else (grouping_values,))\n",
    "                }) for grouping_values, group_data_frame in grouped_persons]\n",
    "    \n",
    "    return pd.DataFrame([row_dict for row_dict in itertools.chain(\n",
    "                *[json.loads(lz4.loads(result)) for result in result_list])])\n",
    "\n",
    "# check this out for a little background:\n",
    "# http://stackoverflow.com/questions/26187759/parallelize-apply-after-pandas-groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = range(100)\n",
    "tic = time.time()\n",
    "r = apply_query_infections(population, households, times=times,\n",
    "                           group_by_keys=['age_group','gender'],\n",
    "                           parallel=True)\n",
    "print(time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_columns(r):\n",
    "    # conversion of columns done as side-effect; data frame passed by ref\n",
    "    if ('gender' in r.keys() and \n",
    "        not all([a==b for (a,b) in zip(sorted(r.gender.unique()),\n",
    "                                       sorted(['M','F']))])):\n",
    "        r.gender = pd.cut(r.gender,bins=2,labels=['M','F'])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convert_columns(r).to_hdf('output.hdf5', key='AlleghenyCounty_42003_100_Days',\n",
    "                          mode='w', format='t', complevel=9, complib='bzip2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
