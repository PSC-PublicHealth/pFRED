{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_infection_events_to_data_frame(filename='infection.events.json'):\n",
    "    def read_infection_events():\n",
    "        with open(filename, 'rb') as f:\n",
    "            for line in f:\n",
    "                yield(json.loads(line))\n",
    "    infections = pd.DataFrame.from_dict(read_infection_events())\n",
    "    infections.loc[infections.symptomatic < 1, 'symptomatic'] = None\n",
    "    return(infections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit -n1 -r1\n",
    "infections = read_infection_events_to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%timeit -n1 -r1\n",
    "population = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_synth_people.txt')\n",
    "households_original = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_synth_households.txt')\n",
    "workplaces = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_workplaces.txt')\n",
    "schools = pd.DataFrame.from_csv('../populations/2005_2009_ver2_42003/2005_2009_ver2_42003_schools.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "households = households_original.reset_index(level=0)\n",
    "households['stcotr'] = (households.stcotrbg/10).astype(np.int64)\n",
    "#population['stcotr'] = (population.stcotrbg/10).astype(np.int64)\n",
    "\n",
    "apollo_locations = pd.DataFrame.from_csv('ApolloLocationCode.to.FIPSstcotr.csv')\n",
    "apollo_locations.reset_index(level=0, inplace=True)\n",
    "\n",
    "households = pd.merge(households, apollo_locations, on='stcotr', how='inner', suffixes=('','_'), copy=True)\n",
    "#population = pd.merge(population, apollo_locations, on='stcotr', how='inner', suffixes=('','_'), copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict = dict(\n",
    "    S = 'susceptible', E = 'exposed', I = 'infectious',\n",
    "    Y = 'symptomatic', R = 'recovered', IS = 'infectious and symptomatic'\n",
    ")\n",
    "population_dict = dict(\n",
    "    person = 'p_id',\n",
    "    race = 'race',\n",
    "    age = 'age',\n",
    "    sex = 'sex'\n",
    ")\n",
    "household_dict = dict(\n",
    "    income = 'hh_income',\n",
    "    location = 'apollo_location_code'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_population(population, households,\n",
    "                     population_attributes=['age','race','sex'],\n",
    "                     household_attributes=['income','location']):\n",
    "    _population_attributes = [population_dict[x] for x in population_attributes] \n",
    "    _household_attributes = [household_dict[x] for x in household_attributes]\n",
    "    #population = population[_population_attributes+['hh_id',]].join(households[_household_attributes],\n",
    "    #               on='hh_id', lsuffix='', rsuffix='.h',\n",
    "    #               how='left')[list(set(_population_attributes).union(_household_attributes))].reset_index(level=0)\n",
    "    population = pd.merge(population.reset_index(level=0)[_population_attributes+['p_id','hh_id',]],\n",
    "                          households.reset_index(level=0)[_household_attributes+['hh_id']],\n",
    "                          on='hh_id', suffixes=('', '.h'), how='left',\n",
    "                          copy=True)[list(set(_population_attributes + ['p_id']\n",
    "                                             ).union(_household_attributes))]\n",
    "    population.rename(columns = {v:k for k,v in dict(population_dict.items() + household_dict.items()).iteritems()},\n",
    "                      inplace = True)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query_infections(infections, times, incidence=['S','E','I','Y','R','IS'],\n",
    "                     prevalence=['S','E','I','Y','R','IS'], grouping_keys={}):\n",
    "    # NOTE: Can't do a join inside a Parallel for some reason, so must join infections and persons before passing!!!\n",
    "    total_susceptible = len(infections.person.unique())\n",
    "    \n",
    "    def get_incidence(infections, state, day):\n",
    "        if state == 'IS':\n",
    "            return len(infections[(day == infections.infectious) & (day == infections.symptomatic)].index)\n",
    "        else:\n",
    "            s = state_dict[state]\n",
    "            return len(infections[infections[s]==day].index)\n",
    "\n",
    "    def get_prevalence(infections, states, day):\n",
    "        if states is not None and isinstance(states, list) and len(states) > 0:\n",
    "            mask = {'NOT_S': (day >= infections.exposed) & (day < infections.susceptible)}\n",
    "            if set(['E','I','Y','R','IS']).intersection(set(states)):\n",
    "                mask['E'] = (mask['NOT_S'] & (day < infections.infectious))\n",
    "            if 'I' in states:\n",
    "                mask['I'] = (mask['NOT_S'] & (day >= infections.infectious)) & (day < infections.recovered)\n",
    "            if 'Y' in states:\n",
    "                mask['Y'] = (mask['NOT_S'] & (day >= infections.symptomatic)) & (day < infections.recovered)\n",
    "            if 'R' in states:\n",
    "                mask['R'] = (mask['NOT_S'] & (day >= infections.recovered)) & (day < infections.susceptible)\n",
    "            if 'IS' in states:\n",
    "                mask['IS'] = mask['I'] & mask['Y']\n",
    "           \n",
    "        for state in states:\n",
    "            if state is None:\n",
    "                raise Exception('No state specified!')\n",
    "            elif state == 'S':\n",
    "                yield (state, total_susceptible - len(infections[mask['NOT_S']].index))\n",
    "            else:\n",
    "                try:\n",
    "                    yield (state, len(infections[mask[state]].index))\n",
    "                except:\n",
    "                    raise Exception('Unknown prevalence state requested %s!' % state)\n",
    "\n",
    "    rows = []\n",
    "    for t in times:\n",
    "        row = dict(day = t)\n",
    "        row.update({k + '_i': get_incidence(infections, k, t) for k in incidence})\n",
    "        row.update({k + '_p': v for k,v in get_prevalence(infections, prevalence, t)})\n",
    "        if grouping_keys:\n",
    "            row.update(grouping_keys)\n",
    "        rows.append(row)\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parallel_apply_query_infections(population, households, infections, times,\n",
    "                                    incidence=['S','E','I','Y','R','IS'],\n",
    "                                    prevalence=['S','E','I','Y','R','IS'],\n",
    "                                    group_by_keys=['age','race']):\n",
    "    \n",
    "    n_jobs = multiprocessing.cpu_count()\n",
    "    \n",
    "    grouped_persons = query_population(population, households).groupby(group_by_keys)\n",
    "    grouping_keys = grouped_persons.grouper.names\n",
    "    \n",
    "    result_list = Parallel(n_jobs=n_jobs)(delayed(query_infections)(\n",
    "            #infections.join(group_data_frame, on='person', how='inner', lsuffix='', rsuffix='_'),\n",
    "            pd.merge(infections, group_data_frame, on='person', how='inner', suffixes=('','_'), copy=False),\n",
    "            times, incidence, prevalence,\n",
    "            {k:v for k,v in zip(grouping_keys,\n",
    "                                grouping_values if isinstance(grouping_values, tuple) \\\n",
    "                                                else (grouping_values,))\n",
    "            }) for grouping_values, group_data_frame in grouped_persons)\n",
    "    \n",
    "    return pd.concat(result_list)\n",
    "# check this out for a little background:\n",
    "# http://stackoverflow.com/questions/26187759/parallelize-apply-after-pandas-groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "r = parallel_apply_query_infections(population, households, infections,\n",
    "                                    times=range(10),\n",
    "                                    #incidence=['E'], prevalence=['I'],\n",
    "                                    group_by_keys=['location','age','sex'])\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(toc-tic)\n",
    "print(len(r))\n",
    "print(r.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.to_csv('test_trajectories.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_population(population, households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "households.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_population(population, households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
